{"cells":[{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.io.wavfile as io_wav\n","import os\n","import glob\n","import pickle\n","import cv2\n","from cv2 import VideoWriter, VideoWriter_fourcc\n","import librosa\n","from keras.models import model_from_json\n","from keras import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n","from keras.metrics import MeanSquaredError\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, model_from_json\n","from tensorflow.keras.saving import register_keras_serializable\n","from tensorflow.keras import backend as K\n","import subprocess  # Add this import\n","from subprocess import run\n"],"metadata":{"id":"eBnqyfqg4jO8","executionInfo":{"status":"ok","timestamp":1728118435926,"user_tz":-330,"elapsed":9807,"user":{"displayName":"MANDAVA KASHYAP SAI IIIT Dharwad","userId":"11386888594398025082"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","    except RuntimeError as e:\n","        print(e)\n"],"metadata":{"id":"Yalq6UVh5KCP","executionInfo":{"status":"ok","timestamp":1728118568538,"user_tz":-330,"elapsed":513,"user":{"displayName":"MANDAVA KASHYAP SAI IIIT Dharwad","userId":"11386888594398025082"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["\n","# from LipReading with slight modifications\n","# https://github.com/hassanhub/LipReading/blob/master/codes/data_integration.py\n","################## VIDEO INPUT ##################\n","def load_video_3D(path, framesPerSec):\n","\n","    cap = cv2.VideoCapture(path)\n","    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT ))\n","    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH ))\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","    # make sure that all the videos are the same FPS\n","    if (np.abs(fps - framesPerSec) > 0.01):\n","        print('fps:', fps, '(' + path + ')')\n","        buf = np.empty((frameHeight, frameWidth, frameCount), np.dtype('float32'))\n","\n","    buf = np.empty((frameHeight, frameWidth, frameCount), np.dtype('float32'))\n","    fc = 0\n","    ret = True\n","\n","    while (fc < frameCount  and ret):\n","        ret, frame = cap.read()\n","        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        frame = frame.astype('float32')\n","        # min-max scaling to [0-1]\n","        frame = frame-np.amin(frame)\n","        # make sure not to divide by zero\n","        if np.amax(frame) != 0:\n","            frame = frame/np.amax(frame)\n","        buf[:,:,fc]=frame\n","        fc += 1\n","    cap.release()\n","\n","    return buf\n","\n","# load vocoder features,\n","# or calculate, if they are not available\n","def get_mgc_lsp_coeff(basefilename):\n","    if os.path.isfile(basefilename + '.mgclsp'):\n","        mgc_lsp_coeff = np.fromfile(basefilename + '.mgclsp', dtype=np.float32).reshape(-1, order + 1)\n","        lf0 = np.fromfile(basefilename + '.lf0', dtype=np.float32)\n","    else:\n","        (mgc_lsp_coeff, lf0) = vocoder_LSP_sptk.encode(basefilename, samplingFrequency, frameLength, frameShift, order, alpha, stage)\n","    return (mgc_lsp_coeff, lf0)\n","\n","# convert an array of values into a dataset matrix\n","# code with modifications from\n","# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n","def create_dataset_img(data_in_X, data_in_Y, look_back=1):\n","    (dim1_X, dim2_X, dim3_X, dim4_X) = data_in_X.shape\n","    (dim1_Y, dim2_Y) = data_in_Y.shape\n","    data_out_X = np.empty((dim1_X - look_back - 1, look_back, dim2_X, dim3_X, dim4_X))\n","    data_out_Y = np.empty((dim1_Y - look_back - 1, dim2_Y))\n","\n","    for i in range(dim1_X - look_back - 1):\n","        for j in range(look_back):\n","            data_out_X[i, j] = data_in_X[i + j]\n","        data_out_Y[i] = data_in_Y[i + j]\n","    return data_out_X, data_out_Y\n","\n","# convert an array of values into a dataset matrix\n","# code with modifications from\n","# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n","def create_dataset_img_inverse(data_in_X, data_in_Y, look_back=1):\n","    (dim1_X, dim2_X) = data_in_X.shape\n","    (dim1_Y, dim2_Y, dim3_Y, dim4_Y) = data_in_Y.shape\n","    data_out_X = np.empty((dim1_X - look_back - 1, look_back, dim2_X))\n","    data_out_Y = np.empty((dim1_Y - look_back - 1, dim2_Y, dim3_Y, dim4_Y))\n","\n","    for i in range(dim1_X - look_back - 1):\n","        for j in range(look_back):\n","            data_out_X[i, j] = data_in_X[i + j]\n","        data_out_Y[i] = data_in_Y[i + j]\n","    return data_out_X, data_out_Y\n","\n","# mri2vid converts raw MRI data to .mp4 video\n","def mri2vid(mri_data, dir_file, filename_no_ext, n_width, n_height, FramesPerSec):\n","\n","    print(filename_no_ext + ' - MRI video started')\n","\n","    output_file_no_ext = dir_file + filename_no_ext\n","    n_frames = len(mri_data)\n","\n","    # compressed\n","    # fourcc = VideoWriter_fourcc(*'MP4V')\n","\n","    # uncompressed 8-bit\n","    fourcc = VideoWriter_fourcc(*'Y800')\n","    video = VideoWriter(output_file_no_ext + '.avi', fourcc, float(FramesPerSec), (n_width, n_height), 0)\n","\n","    for n in range(n_frames):\n","        frame = np.uint8(255 * mri_data[n]).reshape(n_width, n_height, 1)\n","\n","        video.write(frame)\n","        print('frame ', n, ' done', end='\\r')\n","\n","    video.release()\n","\n","    print(filename_no_ext + ' - MRI video finished')\n","\n","def mrividwav2demo(dir_mri, file_mri, dir_wav, file_wav):\n","    # \"-codec copy \" + \\\n","    command = \"ffmpeg \" + \\\n","           \"-y \" + \\\n","           \"-i \" + dir_mri + file_mri + \" \" + \\\n","           \"-i \" + dir_wav + file_wav + \" \" + \\\n","           \"-shortest \" + \\\n","           \"-acodec copy -vcodec copy \" + \\\n","            dir_mri + file_mri[:-4] + \"_with_audio.avi\"\n","           # \"-c:v h264 -crf 20 -c:a aac -strict -2 \" + \\\n","           # \"-filter:v \\\"crop=820:496:215:48\\\" \" + \\\n","\n","    print(command)\n","    run(command, shell=True)"],"metadata":{"id":"Rh8kx2vS5WT6","executionInfo":{"status":"ok","timestamp":1728118616796,"user_tz":-330,"elapsed":426,"user":{"displayName":"MANDAVA KASHYAP SAI IIIT Dharwad","userId":"11386888594398025082"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VNAkGT9Q5x51","executionInfo":{"status":"ok","timestamp":1728118751320,"user_tz":-330,"elapsed":21613,"user":{"displayName":"MANDAVA KASHYAP SAI IIIT Dharwad","userId":"11386888594398025082"}},"outputId":"7203fb7d-eef0-4f46-ec3b-e830433d1045"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\n","# speakerlist = ['F1']\n","# model_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/models/Models_for_Text2MRI/'\n","# # output_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/generated_image_sequence/'\n","# output_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/generated_image_sequence_original_audio/'\n","\n","\n","# # Input_audio_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/audio_files_for_input/'\n","# Input_audio_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/original_audio_files/'\n","\n","\n","\n","speakerlist = ['M2']\n","model_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/models_speech2mri_2024/'\n","# output_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/testing_models/'\n","output_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/temp_image_sequence/'\n","\n","# Input_audio_path = '/content/drive/MyDrive/GAN_based_models/wav_files/'\n","Input_audio_path = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/original_audio_files/'\n","\n","\n","speakerInd = 0\n","# for speaker in ['f1']: # ['f1', 'f2', 'm1', 'm2']:\n","for speaker in speakerlist:\n","    # TODO: modify this according to your data path\n","    # dir_mri = '/content/drive/MyDrive/backup_PhD/database/MRI_USC/data/' + speaker + '/avi/'\n","    dir_mri_test = '/content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/temp_image_sequence/' + speaker + '/'\n","\n","    if not os.path.exists(dir_mri_test):\n","        os.makedirs(dir_mri_test)\n","\n","    # Parameters of vocoder\n","    samplingFrequency = 20000\n","    frameLength = 1024 #\n","    frameShift = 863 # 43.14 ms at 20000 Hz sampling, correspondong to 23.18 fps (MRI video)\n","    order = 24\n","    alpha = 0.42\n","    stage = 3\n","    n_mgc = order + 1\n","\n","    # context window of LSTM\n","    n_sequence = 10\n","\n","    # properties of MRI videos\n","    framesPerSec = 23.18\n","    n_width = 68\n","    n_height = 68\n","\n","    # modelbasenames = [ 'SPEECH2MRI_LSTM_baseline_Text2MRI_M2_2023-04-18_10-55-58',\n","    #           'SPEECH2MRI_LSTM_baseline_Text2MRI_M3_2023-04-18_12-28-25',\n","    #           'SPEECH2MRI_LSTM_baseline_Text2MRI_F1_2023-04-18_13-44-16',\n","    #           'SPEECH2MRI_LSTM_baseline_F2_2024-10-04_10-04-46']\n","\n","    modelbasenames = [ 'SPEECH2MRI_LSTM_baseline_F1_2024-10-04_09-57-40',\n","                      'SPEECH2MRI_LSTM_baseline_F2_2024-10-04_10-04-46',\n","                       'SPEECH2MRI_LSTM_baseline_M2_2024-10-04_09-33-21',\n","                       'SPEECH2MRI_LSTM_baseline_M3_2024-10-04_09-52-15']\n","\n","\n","    # DNN_types = ['FC-DNN_baseline', 'CNN', 'LSTM']\n","    #DNN_types = ['FC-DNN_baseline']\n","    # DNN_types = ['LSTM-CNN']\n","    DNN_types = ['LSTM']\n","    # basefilenames_mri_test = ['usctimit_mri_' + speaker.lower() + '_146_150', 'usctimit_mri_' + speaker.lower() + '_441_445']\n","    basefilenames_mri_test = glob.glob(Input_audio_path +\"/\"+ speaker +'/*.wav')\n","\n","    for DNN_type in DNN_types:\n","        # e.g. MRI2SPEECH_CNN_f1_2020-01-16_10-36-35\n","        # csv_files = glob.glob('/content/drive/MyDrive/GAN_based_models/speech2mri/models/SPEECH2MRI_' + DNN_type + '_baseline_Text2MRI_' + speaker + '*.csv')\n","        csv_files = glob.glob(model_path + modelbasenames[speakerInd] +'*.csv')\n","        model_name = csv_files[-1][:-4]\n","\n","        speakerInd = speakerInd + 1\n","        # load model\n","        print('loading model', model_name)\n","        with open(model_name + '_model.json', \"r\") as json_file:\n","            loaded_model_json = json_file.read()\n","        # model = model_from_json(loaded_model_json)\n","\n","        model = model_from_json(loaded_model_json, custom_objects={'Sequential': Sequential})\n","        model.load_weights(model_name + '_weights.keras')\n","        print(\"Loaded model from disk\")\n","        # load weights into new model\n","        # model.load_weights(model_name + '_weights.h5')\n","        # load scalers\n","        mgc_scalers = pickle.load(open(model_name + '_mgc_scalers.sav', 'rb'))\n","\n","        for basefilename in basefilenames_mri_test:\n","            print('Predicting output for: ', basefilename)\n","\n","            # load data for sentence\n","            # mri_data = load_video_3D(dir_mri + basefilename + '.avi', framesPerSec)\n","            # mri_len = mri_data.shape[2]\n","            # mri_test = np.empty((mri_len, n_width, n_height))\n","            # (mgc_lsp_coeff, lf0) = get_mgc_lsp_coeff(dir_mri + basefilename)\n","            # dir_mri_wav_only = dir_mri.replace('/avi/','/wav/')\n","            # dir_mri_wav = dir_mri_wav_only + basefilename+'.wav'\n","            dir_mri_wav = basefilename\n","            basefilename_name_only = basefilename.split('/')\n","            basefilename_name_only = basefilename_name_only[-1]\n","            basefilename_name_only = basefilename_name_only.replace('.wav', '')\n","\n","            print(basefilename_name_only)\n","            x, sr = librosa.load(dir_mri_wav, sr = samplingFrequency)\n","            n_fft = frameLength   # window length: 0.02 s\n","            hop_length = frameShift  #\n","            mgc_lsp_coeff = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=25, hop_length=hop_length, n_fft=n_fft)\n","            mgc_lsp_coeff = mgc_lsp_coeff.transpose()\n","\n","\n","\n","            # for i in range(mri_len):\n","            #     mri_test[i] = mri_data[:, :, i] # original, 68x68\n","\n","            # transform of input parameters\n","            for i in range(n_mgc):\n","                mgc_lsp_coeff[:, i] = mgc_scalers[i].transform(mgc_lsp_coeff[:, i].reshape(-1, 1)).ravel()\n","\n","            # reshape for LSTM\n","            if DNN_type == 'LSTM' or DNN_type == 'LSTM-CNN':\n","                mgc_len = len(mgc_lsp_coeff)\n","                mri0 = np.empty((mgc_len, n_width, n_height, 1))\n","\n","                mgc_test0, mri0 = create_dataset_img_inverse(mgc_lsp_coeff, mri0, look_back = n_sequence)\n","                mri0 = mri0.reshape(-1, n_width * n_height)\n","                mgc_test = np.empty((mgc_len, n_sequence, n_mgc))\n","\n","                # # add first n_sequence values\n","                # for i in range(mgc_len - 2):\n","                #     if i < n_sequence - 0:\n","                #         mgc_test[i] = mgc_test0[0]\n","                #     else:\n","                #         mgc_test[i] = mgc_test0[i - n_sequence + 1]\n","\n","                # mgc_lsp_coeff = mgc_test\n","\n","            mgc_lsp_coeff = mgc_test0\n","            # predict MR image sequence using the trained model\n","            mri_predicted = model.predict(mgc_lsp_coeff)\n","            print('Prediction done')\n","            # clip extreme values\n","            mri_predicted = np.clip(mri_predicted, 0, 1)\n","\n","            print(mri_predicted.shape)\n","\n","            y_pred = mri_predicted\n","            y_true = mri0\n","\n","            # # Calculating the error\n","            # FrameErr = np.zeros((y_true.shape[0],1))\n","            # for i in range(y_true.shape[0]):\n","            #   t1 = y_pred[i,:]\n","            #   t2 = y_true[i,:]\n","            #   terr =np.mean((np.square(t1-t2)))\n","            #   FrameErr[i]=terr\n","\n","            # MSErr = np.mean(FrameErr)\n","            # print(MSErr)\n","\n","            # MSErr_fn = mean_squared_error(y_pred, y_true)\n","            # print(np.mean(MSErr_fn))\n","\n","\n","            # save image sequence to video (without audio)\n","            mri2vid(mri_predicted, dir_mri_test, basefilename_name_only + '_' + DNN_type, n_width, n_height, framesPerSec)\n","\n","            dir_mri_wav_only = Input_audio_path + speaker +'/'\n","            # put together video and audio\n","            mrividwav2demo(dir_mri_test, basefilename_name_only + '_' + DNN_type + '.avi', \\\n","                dir_mri_wav_only, basefilename_name_only + '.wav')\n","\n","\n"],"metadata":{"id":"iLOtDE_owIsa","colab":{"base_uri":"https://localhost:8080/","height":526},"outputId":"4e91563e-b8c5-4af9-9e8c-bfa474bb9209"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading model /content/drive/MyDrive/GAN_based_models/speech2mri/models_speech2mri_2024/SPEECH2MRI_LSTM_baseline_F1_2024-10-04_09-57-40\n","Loaded model from disk\n","Predicting output for:  /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/original_audio_files/F1/usctimit_mri_f1_441_445.wav\n","usctimit_mri_f1_441_445\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 21s/step\n","Prediction done\n","(591, 4624)\n","usctimit_mri_f1_441_445_LSTM - MRI video started\n","usctimit_mri_f1_441_445_LSTM - MRI video finished\n","ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/temp_image_sequence/F1/usctimit_mri_f1_441_445_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/original_audio_files/F1/usctimit_mri_f1_441_445.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/temp_image_sequence/F1/usctimit_mri_f1_441_445_LSTM_with_audio.avi\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'run' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-187446f9bbe7>\u001b[0m in \u001b[0;36m<cell line: 231>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mdir_mri_wav_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput_audio_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mspeaker\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;31m# put together video and audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             mrividwav2demo(dir_mri_test, basefilename_name_only + '_' + DNN_type + '.avi', \\\n\u001b[0m\u001b[1;32m    374\u001b[0m                 dir_mri_wav_only, basefilename_name_only + '.wav')\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-187446f9bbe7>\u001b[0m in \u001b[0;36mmrividwav2demo\u001b[0;34m(dir_mri, file_mri, dir_wav, file_wav)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"]}]},{"cell_type":"code","source":["\n","import subprocess\n","from subprocess import run\n","mrividwav2demo(dir_mri_test, basefilename_name_only + '_' + DNN_type + '.avi', \\\n","                dir_mri_wav_only, basefilename_name_only + '.wav')\n"],"metadata":{"id":"kyYzI0LtAUj8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a15d52dc-67eb-45b5-8f05-50d7e56a57e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ffmpeg -y -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/temp_image_sequence/F1/usctimit_mri_f1_441_445_LSTM.avi -i /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/original_audio_files/F1/usctimit_mri_f1_441_445.wav -shortest -acodec copy -vcodec copy /content/drive/MyDrive/GAN_based_models/speech2mri/Video_generation_code_for_NCC_paper/temp_image_sequence/F1/usctimit_mri_f1_441_445_LSTM_with_audio.avi\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yL3arNjNf3D1"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}